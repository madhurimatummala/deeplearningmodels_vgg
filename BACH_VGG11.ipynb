{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w09pOhP0DW-z"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import fnmatch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "imagePatches = glob('IDC_regular_ps50_idx5/**/*.png', recursive=True)\n",
    "patternZero = '*class0.png'\n",
    "patternOne = '*class1.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "peHpCamPDW-1"
   },
   "outputs": [],
   "source": [
    "classZero = fnmatch.filter(imagePatches, patternZero)\n",
    "classOne = fnmatch.filter(imagePatches, patternOne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nvYhlTMLDW-1"
   },
   "outputs": [],
   "source": [
    "def process_images(lowerIndex,upperIndex):\n",
    "\n",
    "    height = 50\n",
    "    width = 50\n",
    "    channels = 3\n",
    "    x = [] \n",
    "    y = [] \n",
    "    for img in imagePatches[lowerIndex:upperIndex]:\n",
    "        \n",
    "        full_size_image = cv2.imread(img)\n",
    "        \n",
    "        image = (cv2.resize(full_size_image, (width,height), interpolation=cv2.INTER_CUBIC))\n",
    "       \n",
    "        x.append(image)\n",
    "        if img in classZero:\n",
    "            y.append(0)\n",
    "        elif img in classOne:\n",
    "            y.append(1)\n",
    "        else:\n",
    "            return\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y7O3li0TDW-2"
   },
   "outputs": [],
   "source": [
    "X,Y = process_images(0,100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "33TGRqgrDW-2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "X = X.astype(np.float32) \n",
    "X /= 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mbHkKCBdDW-2"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nFAoNAEdDW-2",
    "outputId": "22c62bef-b6ad-4680-d858-9e30f8964840"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70901"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2XpiY57tDW-3",
    "outputId": "20bcb15b-e4bb-4489-a5a2-b08c141e6dc6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24844"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.count(1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eRWFCUlPDW-3",
    "outputId": "2790a55d-794f-4821-af3c-cfe567c85f73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60156"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tQNVsplxDW-3",
    "outputId": "04d00fb7-4e31-4db4-9430-0c654e09614e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wpz_rHUeDW-4"
   },
   "outputs": [],
   "source": [
    "X_trainShape = X_train.shape[1]*X_train.shape[2]*X_train.shape[3]\n",
    "X_testShape = X_test.shape[1]*X_test.shape[2]*X_test.shape[3]\n",
    "X_trainFlat = X_train.reshape(X_train.shape[0], X_trainShape)\n",
    "X_testFlat = X_test.reshape(X_test.shape[0], X_testShape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Er0HMQroDW-4"
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "random_under_sampler = RandomUnderSampler(ratio='majority')\n",
    "X_trainRos, Y_trainRos = random_under_sampler.fit_sample(X_trainFlat, y_train)\n",
    "X_testRos, Y_testRos = random_under_sampler.fit_sample(X_testFlat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t4U8RCJKDW-4"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Conv2D, Flatten,MaxPooling2D,Dropout\n",
    "batch_size = 256\n",
    "num_classes = 2\n",
    "epochs = 80\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(50,50,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(Flatten()) #this converts our 3D feature maps to 1D feature vectors for the dense layer below\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_TBBuV6tDW-4"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(lr=0.00001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7MpT6qruDW-4"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=180,\n",
    "    horizontal_flip=True,vertical_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ghuWs2FmDW-4"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint,  EarlyStopping\n",
    "early_stopping_monitor = EarlyStopping(monitor='val_loss', patience=3, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78C7BU-EDW-5"
   },
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I2u5kV-SDW-5"
   },
   "outputs": [],
   "source": [
    "Y_trainRosHot = to_categorical(Y_trainRos, num_classes = 2)\n",
    "Y_testRosHot = to_categorical(Y_testRos, num_classes = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TO2PgPONDW-5"
   },
   "outputs": [],
   "source": [
    "for i in range(len(X_trainRos)):\n",
    "    height, width, channels = 50,50,3,\n",
    "    X_trainRosReshaped = X_trainRos.reshape(len(X_trainRos),height,width,channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0pcUimSxDW-5"
   },
   "outputs": [],
   "source": [
    "for i in range(len(X_testRos)):\n",
    "    height, width, channels = 50,50,3\n",
    "    X_testRosReshaped = X_testRos.reshape(len(X_testRos),height,width,channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QAhMU6GRDW-5",
    "outputId": "a9208f9d-6972-423e-c3b0-c2a2fade315f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hanane\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "C:\\Users\\Hanane\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:724: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/194 [==============================] - 128s 657ms/step - loss: 0.6852 - accuracy: 0.5405 - val_loss: 0.6547 - val_accuracy: 0.6572\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.65475, saving model to best_model.h5\n",
      "Epoch 2/80\n",
      "195/194 [==============================] - 126s 647ms/step - loss: 0.6066 - accuracy: 0.6922 - val_loss: 0.5594 - val_accuracy: 0.7212\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.65475 to 0.55943, saving model to best_model.h5\n",
      "Epoch 3/80\n",
      "195/194 [==============================] - 132s 675ms/step - loss: 0.5364 - accuracy: 0.7497 - val_loss: 0.5230 - val_accuracy: 0.7561\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.55943 to 0.52301, saving model to best_model.h5\n",
      "Epoch 4/80\n",
      "195/194 [==============================] - 137s 700ms/step - loss: 0.5263 - accuracy: 0.7576 - val_loss: 0.5186 - val_accuracy: 0.7599\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.52301 to 0.51862, saving model to best_model.h5\n",
      "Epoch 5/80\n",
      "195/194 [==============================] - 139s 715ms/step - loss: 0.5208 - accuracy: 0.7599 - val_loss: 0.5238 - val_accuracy: 0.7558\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.51862\n",
      "Epoch 6/80\n",
      "195/194 [==============================] - 142s 728ms/step - loss: 0.5156 - accuracy: 0.7641 - val_loss: 0.5142 - val_accuracy: 0.7615\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.51862 to 0.51419, saving model to best_model.h5\n",
      "Epoch 7/80\n",
      "195/194 [==============================] - 146s 747ms/step - loss: 0.5138 - accuracy: 0.7644 - val_loss: 0.5117 - val_accuracy: 0.7623\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.51419 to 0.51172, saving model to best_model.h5\n",
      "Epoch 8/80\n",
      "195/194 [==============================] - 160s 822ms/step - loss: 0.5113 - accuracy: 0.7658 - val_loss: 0.5122 - val_accuracy: 0.7637\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.51172\n",
      "Epoch 9/80\n",
      "195/194 [==============================] - 170s 873ms/step - loss: 0.5075 - accuracy: 0.7673 - val_loss: 0.5083 - val_accuracy: 0.7653\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.51172 to 0.50833, saving model to best_model.h5\n",
      "Epoch 10/80\n",
      "195/194 [==============================] - 161s 826ms/step - loss: 0.5065 - accuracy: 0.7688 - val_loss: 0.5038 - val_accuracy: 0.7658\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.50833 to 0.50380, saving model to best_model.h5\n",
      "Epoch 11/80\n",
      "195/194 [==============================] - 152s 779ms/step - loss: 0.5032 - accuracy: 0.7710 - val_loss: 0.5028 - val_accuracy: 0.7680\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.50380 to 0.50275, saving model to best_model.h5\n",
      "Epoch 12/80\n",
      "195/194 [==============================] - 184s 942ms/step - loss: 0.5001 - accuracy: 0.7733 - val_loss: 0.4997 - val_accuracy: 0.7676\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.50275 to 0.49974, saving model to best_model.h5\n",
      "Epoch 13/80\n",
      "195/194 [==============================] - 183s 939ms/step - loss: 0.4964 - accuracy: 0.7750 - val_loss: 0.4994 - val_accuracy: 0.7680\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.49974 to 0.49943, saving model to best_model.h5\n",
      "Epoch 14/80\n",
      "195/194 [==============================] - 184s 941ms/step - loss: 0.4958 - accuracy: 0.7743 - val_loss: 0.5057 - val_accuracy: 0.7636\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.49943\n",
      "Epoch 15/80\n",
      "195/194 [==============================] - 183s 940ms/step - loss: 0.4926 - accuracy: 0.7759 - val_loss: 0.4904 - val_accuracy: 0.7737\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.49943 to 0.49041, saving model to best_model.h5\n",
      "Epoch 16/80\n",
      "195/194 [==============================] - 160s 820ms/step - loss: 0.4883 - accuracy: 0.7791 - val_loss: 0.4924 - val_accuracy: 0.7722\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.49041\n",
      "Epoch 17/80\n",
      "195/194 [==============================] - 182s 934ms/step - loss: 0.4857 - accuracy: 0.7792 - val_loss: 0.4873 - val_accuracy: 0.7758\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.49041 to 0.48728, saving model to best_model.h5\n",
      "Epoch 18/80\n",
      "195/194 [==============================] - 184s 941ms/step - loss: 0.4809 - accuracy: 0.7833 - val_loss: 0.5015 - val_accuracy: 0.7666\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.48728\n",
      "Epoch 19/80\n",
      "195/194 [==============================] - 186s 954ms/step - loss: 0.4799 - accuracy: 0.7827 - val_loss: 0.5026 - val_accuracy: 0.7673\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.48728\n",
      "Epoch 20/80\n",
      "195/194 [==============================] - 186s 954ms/step - loss: 0.4763 - accuracy: 0.7846 - val_loss: 0.4856 - val_accuracy: 0.7779\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.48728 to 0.48561, saving model to best_model.h5\n",
      "Epoch 21/80\n",
      "195/194 [==============================] - 162s 832ms/step - loss: 0.4736 - accuracy: 0.7863 - val_loss: 0.4947 - val_accuracy: 0.7676\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.48561\n",
      "Epoch 22/80\n",
      "195/194 [==============================] - 137s 702ms/step - loss: 0.4703 - accuracy: 0.7875 - val_loss: 0.5016 - val_accuracy: 0.7683\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.48561\n",
      "Epoch 23/80\n",
      "195/194 [==============================] - 162s 828ms/step - loss: 0.4667 - accuracy: 0.7909 - val_loss: 0.5027 - val_accuracy: 0.7686\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.48561\n"
     ]
    }
   ],
   "source": [
    "training = model.fit_generator(datagen.flow(X_trainRosReshaped,Y_trainRosHot,batch_size=batch_size),steps_per_epoch=len(X_trainRosReshaped) / batch_size, epochs=epochs,validation_data=(X_testRosReshaped, Y_testRosHot), verbose=1, callbacks=[early_stopping_monitor, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uy1AxLHGDW-5"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn import metrics\n",
    "model = load_model('best_model.h5')\n",
    "y_pred_one_hot = model.predict(X_testRosReshaped)\n",
    "y_pred_labels = np.argmax(y_pred_one_hot, axis = 1)\n",
    "y_true_labels = np.argmax(Y_testRosHot,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0V-5NeMiDW-6",
    "outputId": "e50f26eb-3572-49a9-bdce-062ae2f95701"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3191 1064]\n",
      " [ 815 3440]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(y_true=y_true_labels, y_pred=y_pred_labels)\n",
    "print(confusion_matrix)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
